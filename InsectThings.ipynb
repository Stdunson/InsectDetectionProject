{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM72zEgllQKE6mCUZQjVF6r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stdunson/InsectDetectionProject/blob/main/InsectThings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps for Bioscan Script:\n",
        "1. Download data\n",
        "2. Remove the DNA and BIN data, remove all where family is not present\n",
        "3. Load ResNet\n",
        "4. Split Sets\n",
        "5. Train, Validate\n",
        "6. Test and Gather Data\n",
        "\n",
        "# Steps for Insect Foundation Script:\n",
        "1. Download data\n",
        "2. Parse JSON File, remove all where family is not present\n",
        "3. Load ResNet\n",
        "4. Split Sets\n",
        "5. Train, Validate\n",
        "6. Test and Gather Data\n",
        "\n",
        "#Inconsistencies\n",
        "1. Not every data picture has every taxonomic level, so there has to be a way to filter that during gathering. The lowest level that every image consistently has is order, which is really high. We're gonna focus on family-level\n",
        "2. One dataset is JSON and the other is raw images. Shouldn't matter too much buecause I'm gonna have two different training algorithms\n",
        "\n"
      ],
      "metadata": {
        "id": "8wEHouczwKh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installs\n",
        "!pip3 install gdown\n",
        "!pip3 install wget\n",
        "!pip3 install utils\n",
        "!pip3 install bioscan-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wszb2y6VDq31",
        "outputId": "2604a7d9-4c19-457b-9342-5cadf892a78c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.20.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.11.12)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: wget in /usr/local/lib/python3.12/dist-packages (3.2)\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.12/dist-packages (1.0.2)\n",
            "Requirement already satisfied: bioscan-dataset in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from bioscan-dataset) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from bioscan-dataset) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from bioscan-dataset) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from bioscan-dataset) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from bioscan-dataset) (0.24.0+cu126)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->bioscan-dataset) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->bioscan-dataset) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->bioscan-dataset) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.4.0->bioscan-dataset) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->bioscan-dataset) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.4.0->bioscan-dataset) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.4.0->bioscan-dataset) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic Imports\n",
        "import os\n",
        "import itertools\n",
        "import gdown\n",
        "\n",
        "#Pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "#Resnet\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n"
      ],
      "metadata": {
        "id": "Fp4Wn6s-ClKh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Downloading"
      ],
      "metadata": {
        "id": "CbWZ_uY3ETvX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "47WTiIiawIHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fee0da-edaa-474f-a9dc-f09a442f51b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File missing: /root/Datasets/bioscan-5m/bioscan5m/metadata/csv/BIOSCAN_5M_Insect_Dataset_metadata.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.07G/2.07G [00:21<00:00, 98.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image directory missing: /root/Datasets/bioscan-5m/bioscan5m/images/cropped_256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.22G/2.22G [00:23<00:00, 95.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata CSV file already downloaded and verified\n",
            "Directory missing: /root/Datasets/bioscan-5m/bioscan5m/images/cropped_256/test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.47G/1.47G [00:20<00:00, 72.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata CSV file already downloaded and verified\n",
            "Images already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Bioscan\n",
        "from bioscan_dataset import BIOSCAN5M\n",
        "\n",
        "# Define the transformations for ResNet50\n",
        "# ResNet50_Weights.IMAGENET1K_V2.transforms() provides the recommended transformations for the pre-trained ResNet50\n",
        "transform = ResNet50_Weights.IMAGENET1K_V2.transforms()\n",
        "\n",
        "bioscan_dataset_train = BIOSCAN5M(\"~/Datasets/bioscan-5m\", download=True, split=\"train\", modality=\"image\", target_type=\"family\", target_format=\"index\", transform=transform)\n",
        "bioscan_dataset_test = BIOSCAN5M(\"~/Datasets/bioscan-5m\", download=True, split=\"test\", modality=\"image\", target_type=\"family\", target_format=\"index\", transform=transform)\n",
        "bioscan_dataset_val = BIOSCAN5M(\"~/Datasets/bioscan-5m\", download=True, split=\"val\", modality=\"image\", target_type=\"family\", target_format=\"index\", transform=transform)\n",
        "#To get class from int: idx_to_class\n",
        "\n",
        "#Information about bioscan_dataset: https://github.com/bioscan-ml/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bioscan Things"
      ],
      "metadata": {
        "id": "oyllqWBEIXaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Resnet\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "bioscan_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).to(device)\n",
        "print(f\"ResNet50 model loaded on device: {device}\")"
      ],
      "metadata": {
        "id": "EAqDHmIuIzDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24496c3-86f0-45ad-d2cb-26960741749d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 225MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet50 model loaded on device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b472193c",
        "outputId": "a03abde6-0d3a-41b3-f31a-2c598f969c00"
      },
      "source": [
        "#Data loaders\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# 1. Initialize DataLoader for bioscan_dataset_train\n",
        "train_dataloader = DataLoader(\n",
        "    bioscan_dataset_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "# 2. Initialize DataLoader for bioscan_dataset_val\n",
        "val_dataloader = DataLoader(\n",
        "    bioscan_dataset_val,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "# 3. Initialize DataLoader for bioscan_dataset_test\n",
        "test_dataloader = DataLoader(\n",
        "    bioscan_dataset_test,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS\n",
        ")\n",
        "\n",
        "print(f\"Created DataLoader with batch size: {BATCH_SIZE}\")\n",
        "\n",
        "# Verify one batch\n",
        "for images, labels in train_dataloader:\n",
        "    print(f\"Batch image shape: {images.shape}\")\n",
        "    print(f\"Batch label shape: {len(labels)}\")\n",
        "    break # Just take one batch to verify"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created DataLoader with batch size: 32\n",
            "Batch image shape: torch.Size([32, 3, 224, 224])\n",
            "Batch label shape: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze ResNet50 layers\n",
        "\n",
        "num_classes = 934\n",
        "\n",
        "#Get amt of in features of last layes\n",
        "in_features = bioscan_model.fc.in_features\n",
        "print(f\"Original ResNet50 FC layer in_features: {in_features}\")\n",
        "\n",
        "#Replace Last Layer\n",
        "bioscan_model.fc = nn.Linear(in_features, num_classes)\n",
        "print(f\"Replaced bioscan_model.fc with new nn.Linear layer (in_features={in_features}, out_features={num_classes})\")\n",
        "\n",
        "#Freeze parameters of pre-trained bioscan_model, then unfreeze only the parameters of classification head\n",
        "for param in bioscan_model.parameters():\n",
        "    param.requires_grad = False\n",
        "print(\"Froze all parameters of the base ResNet50 model.\")\n",
        "for param in bioscan_model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "print(\"Unfroze parameters of the new classification head (bioscan_model.fc).\")\n",
        "\n",
        "#Verify\n",
        "trainable_params = [name for name, param in bioscan_model.named_parameters() if param.requires_grad]\n",
        "print(f\"Number of trainable parameters: {len(trainable_params)}\")\n",
        "print(f\"Trainable layers: {trainable_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXmP91-5psX-",
        "outputId": "9fe4f836-c01a-48db-b8cb-561435c8c365"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original ResNet50 FC layer in_features: 2048\n",
            "Replaced bioscan_model.fc with new nn.Linear layer (in_features=2048, out_features=934)\n",
            "Froze all parameters of the base ResNet50 model.\n",
            "Unfroze parameters of the new classification head (bioscan_model.fc).\n",
            "Number of trainable parameters: 2\n",
            "Trainable layers: ['fc.weight', 'fc.bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define loss funtction & optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(f\"Loss function (criterion) set to: {criterion}\")\n",
        "\n",
        "optimizer = optim.Adam(bioscan_model.fc.parameters(), lr=0.001)\n",
        "print(f\"Optimizer set to: {optimizer}\")"
      ],
      "metadata": {
        "id": "LQsQGb0lsSEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bff2f47-7f8c-4823-c167-22d11b742425"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function (criterion) set to: CrossEntropyLoss()\n",
            "Optimizer set to: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define training loop\n",
        "\n",
        "dataloaders = {'train': train_dataloader, 'validation': val_dataloader, 'test': test_dataloader}\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device).long() # Cast labels to torch.Long\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "hY9ygBrdcMF1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Model\n",
        "bioscan_model.to(device)\n",
        "bioscan_model = train_model(bioscan_model, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM0V3EZ9BFvU",
        "outputId": "9d10fec2-08a8-445c-b0df-fcfc71c8fa2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "train loss: 1.3305, acc: 0.6941\n",
            "validation loss: 0.8976, acc: 0.7747\n",
            "Epoch 2/10\n",
            "----------\n",
            "train loss: 0.8288, acc: 0.7840\n",
            "validation loss: 0.8230, acc: 0.7920\n",
            "Epoch 3/10\n",
            "----------\n",
            "train loss: 0.7095, acc: 0.8090\n",
            "validation loss: 0.8149, acc: 0.7928\n",
            "Epoch 4/10\n",
            "----------\n",
            "train loss: 0.6485, acc: 0.8225\n",
            "validation loss: 0.8127, acc: 0.7975\n",
            "Epoch 5/10\n",
            "----------\n",
            "train loss: 0.6086, acc: 0.8311\n",
            "validation loss: 0.8342, acc: 0.7920\n",
            "Epoch 6/10\n",
            "----------\n",
            "train loss: 0.5818, acc: 0.8371\n",
            "validation loss: 0.8282, acc: 0.7909\n",
            "Epoch 7/10\n",
            "----------\n",
            "train loss: 0.5603, acc: 0.8416\n",
            "validation loss: 0.8274, acc: 0.7983\n",
            "Epoch 8/10\n",
            "----------\n",
            "train loss: 0.5470, acc: 0.8439\n",
            "validation loss: 0.8668, acc: 0.7922\n",
            "Epoch 9/10\n",
            "----------\n",
            "train loss: 0.5332, acc: 0.8477\n",
            "validation loss: 0.8506, acc: 0.7941\n",
            "Epoch 10/10\n",
            "----------\n",
            "train loss: 0.5271, acc: 0.8486\n",
            "validation loss: 0.8616, acc: 0.7958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isaICYyAlrl9",
        "outputId": "57049230-83d6-45ba-a54c-070a7e4a48e1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uStzCtlaB6Hb",
        "outputId": "141cbeea-43b8-4358-c6e0-a5d6bc7549c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Model\n",
        "torch.save(bioscan_model.state_dict(), 'models/bioscan_model.pth')"
      ],
      "metadata": {
        "id": "IMhsWSRUB9Wd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define evaluation/testing loop\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device).long() # Cast labels to torch\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader.dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "    print('Test loss: {:.4f}, acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6T2-AN4bsHtM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Model\n",
        "\n",
        "model = bioscan_model\n",
        "dataloader = test_dataloader\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "evaluate_model(model, dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKA5Rfz3nLT0",
        "outputId": "6a9b3c2e-44fd-4f6b-ba78-b2f1e8d1400b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.3684, acc: 0.6922\n"
          ]
        }
      ]
    }
  ]
}